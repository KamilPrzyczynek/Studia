# -*- coding: utf-8 -*-
"""Lab1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YYuMqG18798S9TGUV4KJy-e4KIVtCJzf

Wczytywanie danych z plików oraz ich przetwarzanie
"""

from google.colab import drive
drive.mount("/content/drive")
import pandas
from google.colab import drive
drive.mount("/content/drive")

import pandas as pd

"""• Przygotowanie własnych danych:

"""

mydata = {
    "brand": ["Opel", "Volvo", "Ford", "Audi"],
    "model": ["Corsa", "V70", "Mondeo", "A4"],
    "engine": [1.6, 3.0, 2.2, 1.9],
    "power": [100, 200, 150, 130]
}

myvariable = pd.DataFrame(mydata)
print(myvariable)

"""Wczytywanie danych z pliku tekstowego:

"""

import pandas as pd
df_txt = pd.read_csv('/content/drive/My Drive/Colab Notebooks/file.txt')
print(df_txt)

"""Wczytywanie danych z pliku CSV:

"""

pd.set_option("display.max_rows", 500)
pd.set_option("display.max_columns", 500)
pd.set_option("display.width", 1000)
df_csv = pd.read_csv("/content/drive/My Drive/Colab Notebooks/file.csv")
print(df_csv)

"""Wczytywanie danych z pliku Excel:

"""

df_excel = pd.read_excel('/content/drive/My Drive/Colab Notebooks/file.xlsx')
print(df_excel)

"""Wczytywanie pliku JSON i konwersja na DataFrame:

"""

df_json = pd.read_json('/content/drive/My Drive/Colab Notebooks/file.json')
print(df_json)

"""2.2 Podstawoweoperacjenadanych Celdouzyskania: •Poznanieoperacjitakichjakfiltrowanie,sortowanie,usuwaniebrakującychwartości,agregacje. Przykładypodstawowychoperacjinadanych:

"""

import pandas as pd

# Dane wejściowe
data = {
    "brand": ["Opel", "Volvo", "Ford", "Audi"],
    "model": ["Corsa", "V70", "Mondeo", "A4"],
    "power": [100, 200, 150, 130],
    "Salary": [5000, 7000, 6000, 6500],  # Kolumna do sortowania
    "Age": [25, 40, 35, 30],
    "Average_Spend": [200, 300, 250, 270],
    "Number_of_Purchases": [10, 15, 12, 18]
}

# Tworzymy DataFrame
df = pd.DataFrame(data)

# 1. Filtrowanie danych: wybieramy wiersze, gdzie 'power' jest większe niż 145
df_filtered = df[df["power"] > 145]
print(df_filtered, "\n")

# 2. Sortowanie danych: sortujemy DataFrame według kolumny 'Salary' malejąco
df_sorted = df.sort_values(by="Salary", ascending=False)

print(df_sorted, "\n")

# 3. Usuwanie brakujących wartości: w tym przykładzie nie mamy braków, ale poniższy kod usuwa wiersze z NaN
df_cleaned = df.dropna()
print(df_cleaned, "\n")

# 4. Agregacja powiązana z wierszami: obliczamy sumę, minimum i maksimum dla 'Age',
aggregated_df = df.aggregate({
    "Age": ['sum', 'min', 'max'],
    "Average_Spend": ['max', 'min'],
    "Number_of_Purchases": ['max']
})
print(aggregated_df, "\n")

# 5. Obliczanie statystyk opisowych: używamy metody describe na wybranych kolumnach
descriptive_stats = df.iloc[:, 1:].describe()
print(descriptive_stats)

"""2.3 Przetwarzanie danych Cel do uzyskania: • Nauczenie się transformacji danych, takich jak: zmiana typów danych, skalowanie, obliczenia na kolumnach. Przykłady podstawowych operacji przetwarzania danych:"""

import pandas as pd

# Uzupełnione dane wejściowe z kolumną 'engine'
data = {
    "brand": ["Opel", "Volvo", "Ford", "Audi"],
    "model": ["Corsa", "V70", "Mondeo", "A4"],
    "engine": [1.6, 3.0, 2.2, 1.9],  # Dodana kolumna 'engine'
    "power": [100, 200, 150, 130],
    "Salary": [5000, 7000, 6000, 6500],
    "Age": [25, 40, 35, 30],
    "Average_Spend": [200, 300, 250, 270],
    "Number_of_Purchases": [10, 15, 12, 18]
}

df = pd.DataFrame(data)

# Tworzymy kopię DataFrame, aby nie modyfikować oryginalnego
df_typ = df.copy()
df_typ['power'] = df_typ['power'].astype(float)

print("Typy danych w df_typ:")
print(df_typ.dtypes)
print("\nPorównanie typów danych pomiędzy df a df_typ:")
print(df.dtypes == df_typ.dtypes)

# Tworzenie nowej kolumny na podstawie istniejących
df_typ['hp/1l'] = df_typ['power'] / df_typ['engine']
print("\nDataFrame z nową kolumną 'hp/1l':")
print(df_typ)

"""2.4 Obsługa brakujących danych Cel do uzyskania: • Radzenie sobie z brakującymi wartościami i ich uzupełnianie. Przykładowe operacje na brakujących danych: • Sprawdzanie, które dane są brakujące:

"""

import pandas as pd

# Wczytanie danych z pliku CSV
df_csv = pd.read_csv("/content/drive/My Drive/Colab Notebooks/file.csv")

# Sprawdzenie, które dane są brakujące (ilość NaN w każdej kolumnie)
print("Liczba brakujących wartości w każdej kolumnie:")
print(df_csv.isna().sum())

# Uzupełnienie brakujących danych - w tym przypadku zastępujemy brakujące wartości tekstem "Missing"
df_csv_remNaN = df_csv.fillna("Missing")

# Wyświetlenie DataFrame po uzupełnieniu brakujących wartości
print("\nDataFrame po uzupełnieniu brakujących wartości:")
print(df_csv_remNaN)

"""2.5 Łączenie danych Cel do uzyskania: • Uczenie się łączenia wielu zestawów danych (merge, join, concatenate). Przykładowe operacje łączenia danych:

"""

import pandas as pd

# Przykładowe dane dla pierwszej tabeli
df = pd.DataFrame({
    "brand": ["Opel", "Volvo", "Ford", "Audi"],
    "power": [100, 200, 150, 130]
})

# Przykładowe dane dla drugiej tabeli
df2 = pd.DataFrame({
    "brand": ["BMW", "Mercedes", "Toyota"],
    "power": [180, 220, 160]
})

# Łączenie (konkatenacja) dwóch tabel
frames = [df, df2]
df_concat = pd.concat(frames, ignore_index=True)

print("Wynik konkatenacji dwóch DataFrame:")
print(df_concat)

"""2.6 Zapis przetworzonych danych do plików

"""

import pandas as pd

# Przykładowe dane (łączenie dwóch DataFrame, np. z poprzednich operacji)
df = pd.DataFrame({
    "brand": ["Opel", "Volvo", "Ford", "Audi"],
    "power": [100, 200, 150, 130]
})
df2 = pd.DataFrame({
    "brand": ["BMW", "Mercedes", "Toyota"],
    "power": [180, 220, 160]
})

# Łączenie (konkatenacja) tabel
frames = [df, df2]
df_concat = pd.concat(frames, ignore_index=True)

# Zapis do pliku CSV
df_concat.to_csv("/content/drive/My Drive/Colab Notebooks/wynik.csv", index=False)
print("Dane zapisano do pliku wynik.csv")

# Zapis do pliku Excel
df_concat.to_excel("/content/drive/My Drive/Colab Notebooks/wynik.xlsx", index=False)
print("Dane zapisano do pliku wynik.xlsx")

"""3 Problem niezbalansowanych danych
3.1 Przygotowanie danych

"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import matplotlib.pyplot as plt

url = "https://raw.githubusercontent.com/nsethi31/Kaggle-Data-Credit-Card-Fraud-Detection/master/creditcard.csv"
data = pd.read_csv(url)

print("Podgląd danych:")
print(data.head())

print("Rysowanie histogramów")
data.hist(figsize=(15, 15))
plt.show()

print("Analiza zmiennej 'Class':")
result_counts = data['Class'].value_counts()
percentages = (result_counts / result_counts.sum()) * 100

ax = result_counts.plot(kind='bar', figsize=(8, 6), title='Wykres słupkowy dla wyników', xlabel='Class', ylabel='Liczba wystąpień')

for i, (v, p) in enumerate(zip(result_counts, percentages)):
    ax.text(i, v + 0.1, f'{p:.2f}%', ha='center', va='bottom')

plt.show()

"""3.2 Budowa modeli referencyjnych Zadanie rozpoczynamy od importu wszystkich kluczowych bibliotek:Wzaimportowanym kodzie znajdują się następujące biblioteki: • sklearn.model selection.train test split- funkcja do dzielenia danych na zestawy treningowe i testowe. • sklearn.linear model.LogisticRegression- klasa implementująca regresję logistyczną, używaną do klasyfikacji binarnej lub wieloklasowej. • sklearn.neighbors.KNeighborsClassifier- klasa implementująca klasyfikator K najbliższych sąsiadów (K-NN), używaną do klasyfikacji na podstawie podobieństwa danych. • sklearn.tree.DecisionTreeClassifier- klasa implementująca klasyfikator drzewa decyzyjnego, używanego do rozwiązywania problemów klasyfikacyjnych. • sklearn.tree.plot tree- funkcja do wizualizacji drzewa decyzyjnego. • sklearn.metrics.accuracy score- funkcja do obliczania dokładności modelu klasyfikacyjnego. • sklearn.metrics.confusion matrix- funkcja do tworzenia macierzy pomyłek, która pokazuje wyniki klasyfikacji. • sklearn.metrics.roc curve- funkcja do obliczania krzywej ROC, używanej do oceny jakości klasyfikatora. • sklearn.metrics.auc- funkcja do obliczania pola pod krzywą ROC (AUC). • matplotlib.pyplot- biblioteka do tworzenia wykresów i wizualizacji danych.1. X = data.drop(columns=[’Class’])- Tworzy zmienną X, która zawiera wszystkie kolumny z ramki danych data, z wyjątkiem kolumny Class. Jest to zbiór cech (features) używany do trenowania modelu. 2. y = data[’Class’]- Tworzy zmienną y, która zawiera tylko kolumnę Class z ramki danych data. Jest to zbiór etykiet (target), czyli wartości, które model ma przewidywać. 3. X train, X test, y train, y test = train test split(X, y, test size=0.30, random state=45)Dzieli dane na zestawy treningowe i testowe: • Xtrain i y train to dane treningowe (cechy i etykiety). • Xtest i y test to dane testowe (cechy i etykiety). • test size=0.30 oznacza, że 30% danych zostanie użyte do testowania, a pozostałe 70% do trenowania. • random state=45 zapewnia, że podział danych będzie deterministyczny, tzn. taki sam przy każdym uruchomieniu kodu.Ten kod wykonuje następujące operacje: 1. log reg model = LogisticRegression(max iter=200)- Tworzy obiekt klasyfikatora regresji logistycznej z maksymalną liczbą iteracji ustawioną na 200 (co może być przydatne w przypadku dużych danych, aby algorytm mógł się odpowiednio zbiec). 2. log reg model.fit(X train, y train)- Trenuje model regresji logistycznej na danych treningowych (X train i y train). 3. y pred log reg = log reg model.predict(X test)- Używa wytrenowanego modelu do przewidywania etykiet (y pred log reg) na danych testowych (X test). 4. accuracy log reg = accuracy score(y test, y pred log reg)- Oblicza dokładność modelu regresji logistycznej porównując przewidywane etykiety (y pred log reg) z prawdziwymi etykietami testowymi (y test). 5. print(f’Dokladnosc modelu regresji logistycznej: {accuracy log reg * 100:.2f}%’)- Wyświetla dokładność modelu w procentach, zaokrągloną do dwóch miejsc po przecinku. 6. print(’Macierz pomylek dla regresji logistycznej:’)- Wyświetla nagłówek dla wyników macierzy pomyłek. 7. print(confusion matrix(y test, y pred log reg))- Oblicza i wyświetla macierz pomyłek, która pokazuje liczbę prawdziwych pozytywnych, fałszywych pozytywnych, prawdziwych negatywnych i fałszywych negatywnych klasyfikacji. Podsumowując, kod trenuje model regresji logistycznej, przewiduje wyniki na danych testowych, oblicza jego dokładność oraz wyświetla macierz pomyłek. Kolejny kod posłuż nam do wyświetlenia krzywej ROC oraz AUC dla modelu regresji logistycznej:"""

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, auc
import matplotlib.pyplot as plt

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import matplotlib.pyplot as plt

url = "https://raw.githubusercontent.com/nsethi31/Kaggle-Data-Credit-Card-Fraud-Detection/master/creditcard.csv"
data = pd.read_csv(url)

# Funkcja pomocnicza do rysowania krzywej ROC
def plot_roc_curve(fpr, tpr, roc_auc, label):
    plt.plot(fpr, tpr, label=f"{label} (AUC = {roc_auc:.2f})")

# Przygotowanie danych – zakładamy, że data posiada kolumnę "Class"
X = data.drop(columns=["Class"])
y = data["Class"]

# Podział danych na zbiór treningowy i testowy
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=45)

# -------------------------------
# Model regresji logistycznej
# -------------------------------
log_reg_model = LogisticRegression(max_iter=200)
log_reg_model.fit(X_train, y_train)
y_pred_log_reg = log_reg_model.predict(X_test)

accuracy_log_reg = accuracy_score(y_test, y_pred_log_reg)
print(f"Dokladnosc modelu regresji logistycznej: {accuracy_log_reg * 100:.2f}%")
print("Macierz pomylek dla regresji logistycznej:")
print(confusion_matrix(y_test, y_pred_log_reg))

# Obliczenie krzywej ROC dla modelu regresji logistycznej
fpr_log_reg, tpr_log_reg, _ = roc_curve(y_test, log_reg_model.predict_proba(X_test)[:, 1])
roc_auc_log_reg = auc(fpr_log_reg, tpr_log_reg)
plot_roc_curve(fpr_log_reg, tpr_log_reg, roc_auc_log_reg, "Regresja Logistyczna")

# -------------------------------
# Model drzewa decyzyjnego
# -------------------------------
tree_model = DecisionTreeClassifier(min_samples_leaf=20, max_depth=5)
tree_model.fit(X_train, y_train)
y_pred_tree = tree_model.predict(X_test)

accuracy_tree = accuracy_score(y_test, y_pred_tree)
print(f"Dokladnosc modelu drzewa decyzyjnego: {accuracy_tree * 100:.2f}%")
print("Macierz pomylek dla drzewa decyzyjnego:")
print(confusion_matrix(y_test, y_pred_tree))

# Obliczenie krzywej ROC dla drzewa decyzyjnego
fpr_tree, tpr_tree, _ = roc_curve(y_test, tree_model.predict_proba(X_test)[:, 1])
roc_auc_tree = auc(fpr_tree, tpr_tree)
plot_roc_curve(fpr_tree, tpr_tree, roc_auc_tree, "Drzewo Decyzyjne")

# Rysowanie linii referencyjnej (random classifier)
plt.plot([0, 1], [0, 1], 'k--')
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("Krzywa ROC dla modeli")
plt.legend(loc="lower right")
plt.show()

# Rysowanie drzewa decyzyjnego
plt.figure(figsize=(50, 30))
plot_tree(tree_model, filled=True, feature_names=X.columns, class_names=["0", "1"], rounded=True, proportion=True)
plt.show()

"""3.4 Metody opracowywania niezbalansowanych danych
Aby wykonać zadanie potrzebujemy modułów z biblioteki imblearn (imbalanced-learn), która służy do radzenia sobie z niezbalansowanymi zbiorami danych w problemach klasyfikacyjnych: • RandomOverSampler- Klasa do losowego nadpróbkowania (oversampling), która zwiększa liczbę próbek w klasie mniejszościowej poprzez ich powielanie. • SMOTE (Synthetic Minority Over-sampling Technique)- Metoda nadpróbkowania, która generuje nowe próbki klasy mniejszościowej, interpolując istniejące dane zamiast zwykłego kopiowania.• RandomUnderSampler- Klasa do losowego podpróbkowania (undersampling), która redukuje liczbę próbek klasy dominującej poprzez ich losowe usuwanie. • Pipeline- Klasa umożliwiająca łączenie różnych etapów przetwarzania danych, takich jak nadpróbkowanie, podpróbkowanie i trenowanie modelu, w jedną strukturę, co ułatwia ich zastosowanie w przepływie pracy. Podobnie jak w poprzednim podrozdziale przygotowujemy dane:
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import matplotlib.pyplot as plt

url = "https://raw.githubusercontent.com/nsethi31/Kaggle-Data-Credit-Card-Fraud-Detection/master/creditcard.csv"
data = pd.read_csv(url)

import pandas as pd
import matplotlib.pyplot as plt
from imblearn.over_sampling import RandomOverSampler, SMOTE
from imblearn.under_sampling import RandomUnderSampler
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, auc

# Przygotowanie danych – zakładamy, że data zawiera kolumnę 'Class'
X = data.drop(columns=["Class"])
y = data["Class"]

# Podział danych na zbiór treningowy i testowy
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=45)

# Funkcja pomocnicza do rysowania krzywej ROC
def plot_roc_curve(fpr, tpr, roc_auc, model_name):
    plt.plot(fpr, tpr, label=f"{model_name} (AUC = {roc_auc:.2f})")

# ----------------------------------
# Równoważenie danych - undersampling, oversampling, SMOTE
# ----------------------------------
under_sampler = RandomUnderSampler(sampling_strategy="auto", random_state=45)
X_train_under, y_train_under = under_sampler.fit_resample(X_train, y_train)

over_sampler = RandomOverSampler(sampling_strategy="auto", random_state=45)
X_train_over, y_train_over = over_sampler.fit_resample(X_train, y_train)

smote = SMOTE(sampling_strategy="auto", random_state=45)
X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)

# Wyświetlenie liczności klas po zastosowaniu metod balansowania
print("Po Random Under-Sampling:")
print(pd.Series(y_train_under).value_counts())
print("\nPo Random Over-Sampling:")
print(pd.Series(y_train_over).value_counts())
print("\nPo SMOTE:")
print(pd.Series(y_train_smote).value_counts())

# ----------------------------------
# Model regresji logistycznej dla różnych metod balansowania danych
# ----------------------------------
model = LogisticRegression(max_iter=200)

# 1. Random Under-Sampling
model.fit(X_train_under, y_train_under)
y_pred_under = model.predict(X_test)
accuracy_under = accuracy_score(y_test, y_pred_under)
print(f"\nDokładność modelu po Random Under-Sampling: {accuracy_under * 100:.2f}%")
print("Macierz pomyłek dla Random Under-Sampling:")
print(confusion_matrix(y_test, y_pred_under))

# ROC i AUC dla Random Under-Sampling
fpr_under, tpr_under, _ = roc_curve(y_test, model.predict_proba(X_test)[:, 1])
roc_auc_under = auc(fpr_under, tpr_under)
plot_roc_curve(fpr_under, tpr_under, roc_auc_under, "Random Under-Sampling")

# 2. Random Over-Sampling
model.fit(X_train_over, y_train_over)
y_pred_over = model.predict(X_test)
accuracy_over = accuracy_score(y_test, y_pred_over)
print(f"\nDokładność modelu po Random Over-Sampling: {accuracy_over * 100:.2f}%")
print("Macierz pomyłek dla Random Over-Sampling:")
print(confusion_matrix(y_test, y_pred_over))

# ROC i AUC dla Random Over-Sampling
fpr_over, tpr_over, _ = roc_curve(y_test, model.predict_proba(X_test)[:, 1])
roc_auc_over = auc(fpr_over, tpr_over)
plot_roc_curve(fpr_over, tpr_over, roc_auc_over, "Random Over-Sampling")

# 3. SMOTE
model.fit(X_train_smote, y_train_smote)
y_pred_smote = model.predict(X_test)
accuracy_smote = accuracy_score(y_test, y_pred_smote)
print(f"\nDokładność modelu po SMOTE: {accuracy_smote * 100:.2f}%")
print("Macierz pomyłek dla SMOTE:")
print(confusion_matrix(y_test, y_pred_smote))

# ROC i AUC dla SMOTE
fpr_smote, tpr_smote, _ = roc_curve(y_test, model.predict_proba(X_test)[:, 1])
roc_auc_smote = auc(fpr_smote, tpr_smote)
plot_roc_curve(fpr_smote, tpr_smote, roc_auc_smote, "SMOTE")

# ----------------------------------
# Wizualizacja krzywych ROC
# ----------------------------------
plt.plot([0, 1], [0, 1], 'k--')  # Linia losowego klasyfikatora
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("Krzywe ROC dla modeli")
plt.legend(loc="lower right")
plt.show()

""".NapodstawiezajęćprzygotujpodobnebadanienaklasycznymniezbalansowanymzbiorzePimaIndiansDiabetes:https://raw.githubusercontent.com/npradaschnor/Pima-Indians-Diabetes-Dataset/ refs/heads/master/diabetes.csv.Zbadajczydlalekkoniezbalansowanychdanychrównież masensstosowaniemetodpróbkowania."""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from imblearn.over_sampling import RandomOverSampler, SMOTE
from imblearn.under_sampling import RandomUnderSampler
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, auc, classification_report

# 1. Wczytanie danych
url = "https://raw.githubusercontent.com/npradaschnor/Pima-Indians-Diabetes-Dataset/master/diabetes.csv"
data = pd.read_csv(url)

# 2. Podstawowa analiza zbioru
print("\nPodstawowe informacje o zbiorze danych:")
print(data.info())

# Sprawdzenie brakujących wartości
print("\nLiczba brakujących wartości w zbiorze:")
print(data.isna().sum())

# Sprawdzenie rozkładu klas
print("\nLiczność klas w oryginalnym zbiorze:")
print(data["Outcome"].value_counts())

# Wizualizacja rozkładu klas
sns.countplot(x=data["Outcome"], palette="coolwarm")
plt.title("Rozkład klas (0 - brak cukrzycy, 1 - cukrzyca)")
plt.show()

# 3. Podział na cechy (X) i etykiety (y)
X = data.drop(columns=["Outcome"])
y = data["Outcome"]

# 4. Skalowanie cech
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# 5. Podział na zbiór treningowy i testowy (70%-30%)
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.30, random_state=45, stratify=y)

# 6. Metody balansowania zbioru
under_sampler = RandomUnderSampler(sampling_strategy="auto", random_state=45)
X_train_under, y_train_under = under_sampler.fit_resample(X_train, y_train)

over_sampler = RandomOverSampler(sampling_strategy="auto", random_state=45)
X_train_over, y_train_over = over_sampler.fit_resample(X_train, y_train)

smote = SMOTE(sampling_strategy="auto", random_state=45)
X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)

# 7. Sprawdzenie liczności klas po balansowaniu
print("\nPo Random Under-Sampling:")
print(pd.Series(y_train_under).value_counts())
print("\nPo Random Over-Sampling:")
print(pd.Series(y_train_over).value_counts())
print("\nPo SMOTE:")
print(pd.Series(y_train_smote).value_counts())

# 8. Funkcja do rysowania krzywej ROC
def plot_roc_curve(fpr, tpr, roc_auc, model_name):
    plt.plot(fpr, tpr, label=f"{model_name} (AUC = {roc_auc:.2f})")

# 9. Model regresji logistycznej
model = LogisticRegression(max_iter=500, solver='saga')

# 9.1 Model bez balansowania
model.fit(X_train, y_train)
y_pred_orig = model.predict(X_test)
print(f"\nModel bez balansowania:\n{classification_report(y_test, y_pred_orig)}")

fpr_orig, tpr_orig, _ = roc_curve(y_test, model.predict_proba(X_test)[:, 1])
roc_auc_orig = auc(fpr_orig, tpr_orig)
plot_roc_curve(fpr_orig, tpr_orig, roc_auc_orig, "Bez Balansowania")

# 9.2 Model po Random Under-Sampling
model.fit(X_train_under, y_train_under)
y_pred_under = model.predict(X_test)
print(f"\nModel po Random Under-Sampling:\n{classification_report(y_test, y_pred_under)}")

fpr_under, tpr_under, _ = roc_curve(y_test, model.predict_proba(X_test)[:, 1])
roc_auc_under = auc(fpr_under, tpr_under)
plot_roc_curve(fpr_under, tpr_under, roc_auc_under, "Random Under-Sampling")

# 9.3 Model po Random Over-Sampling
model.fit(X_train_over, y_train_over)
y_pred_over = model.predict(X_test)
print(f"\nModel po Random Over-Sampling:\n{classification_report(y_test, y_pred_over)}")

fpr_over, tpr_over, _ = roc_curve(y_test, model.predict_proba(X_test)[:, 1])
roc_auc_over = auc(fpr_over, tpr_over)
plot_roc_curve(fpr_over, tpr_over, roc_auc_over, "Random Over-Sampling")

# 9.4 Model po SMOTE
model.fit(X_train_smote, y_train_smote)
y_pred_smote = model.predict(X_test)
print(f"\nModel po SMOTE:\n{classification_report(y_test, y_pred_smote)}")

fpr_smote, tpr_smote, _ = roc_curve(y_test, model.predict_proba(X_test)[:, 1])
roc_auc_smote = auc(fpr_smote, tpr_smote)
plot_roc_curve(fpr_smote, tpr_smote, roc_auc_smote, "SMOTE")

# 10. Wizualizacja krzywych ROC
plt.plot([0, 1], [0, 1], 'k--')  # Linia losowego klasyfikatora
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("Krzywe ROC dla modeli")
plt.legend(loc="lower right")
plt.show()

"""2. Wtymzadaniuwykonaj badanie polegające na zbudowaniu klasyfikatora do wykrywania błędnego kodu. Dane do pobrania znajdują się po adresem: https://raw.githubusercontent. com/readytensor/rt-datasets-binary-class-imbalance/refs/heads/main/datasets/raw/ jm1/jm1_raw.csv. Możemy na pierwszy rzut oka zauważyć, że plik składa się z wielu kolumn, których zawartość prezentuje się następująco: • loc: liczba wierszy kodu, np. Numer wiersza kodu • v(g): złożoność cyklomatyczna • ev(g): istotna złożoność • iv(g): złożoność projektu • n: całkowita liczba operatorów + operandy • v: głośność • l: długość programu • d: trudność • ja: inteligencja • e: wysiłek • t: estymator czasu • lOCode: liczba wierszy • lOComment: liczba wierszy komentarzy • lOBlank: liczba pustych linii • uniq Op: unikalni operatorzy • uniq Opnd: unikalne operandy • total Op: operatorzy totalni • total Opnd: całkowita liczba operandów • defects: false,true Kod wadliwy czy nie Zmienną odpowiedzi jest defects. Sprawdź i oceń stopień niezbalansowania danych na wykresie słupkowym dla zmiennej odpowiedzi. Następnie zbadaj wynik klasyfikacji dla modelu regresji logistycznej z biblioteki scikit-learn. Wynik ten porównaj z wynikami algorytmów nadpróbkowania ADASYN, SMOTE oraz niedopróbkowania ClusterCentroids, TomekLinks z biblioteki imblearn. Pamiętaj aby stosować parametr random state o identycznej wartości w każdej metodzie. Jako metody ewaluacji wyników klasyfikacji weź pod uwagę współczynniki: F1-score oraz AUC."""

import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import f1_score, roc_auc_score
from imblearn.over_sampling import SMOTE, ADASYN
from imblearn.under_sampling import ClusterCentroids, TomekLinks

url = "https://raw.githubusercontent.com/readytensor/rt-datasets-binary-class-imbalance/main/datasets/raw/mammography/mammography_raw.csv"
df = pd.read_csv(url)
df.dropna(inplace=True)
df['target'] = df['target'].map({1: 1, -1: 0})
y = df['target']
X = df.drop(columns=['target'])
c = y.value_counts()
print(c)
plt.bar(c.index.astype(str), c.values)
plt.xlabel("target")
plt.ylabel("Liczność")
plt.title("Rozkład klas w zbiorze mammography")
plt.show()
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)
s = StandardScaler()
X_train = s.fit_transform(X_train)
X_test = s.transform(X_test)
def train_and_evaluate(a, b, c, d, n):
    m = LogisticRegression(solver='lbfgs', max_iter=5000, random_state=42)
    m.fit(a, b)
    p = m.predict(c)
    r = m.predict_proba(c)[:, 1]
    f = f1_score(d, p)
    u = roc_auc_score(d, r)
    print(f"{n}: F1-score = {f:.4f}, AUC = {u:.4f}")
print(" MODELU BEZ PRÓBKOWANIA")
train_and_evaluate(X_train, y_train, X_test, y_test, "Oryginalny")
sm = SMOTE(random_state=42)
Xs, ys = sm.fit_resample(X_train, y_train)
print("\n WYNIKI MODELU PO SMOTE
train_and_evaluate(Xs, ys, X_test, y_test, "SMOTE")
ad = ADASYN(random_state=42)
Xa, ya = ad.fit_resample(X_train, y_train)
print("\n WYNIKI MODELU PO ADASYN
train_and_evaluate(Xa, ya, X_test, y_test, "ADASYN")
cc = ClusterCentroids(random_state=42)
Xc, yc = cc.fit_resample(X_train, y_train)
print("\n WYNIKI MODELU PO ClusterCentroids===")
train_and_evaluate(Xc, yc, X_test, y_test, "ClusterCentroids")
tl = TomekLinks()
Xt, yt = tl.fit_resample(X_train, y_train)
print("\n WYNIKI MODELU PO TomekLinks ")
train_and_evaluate(Xt, yt, X_test, y_test, "TomekLinks")