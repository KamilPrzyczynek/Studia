# -*- coding: utf-8 -*-
"""lab4inzw.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lKQs11lNj91DEIRkjJyalf4eFEcObHfS

. Tokenizacja- polega na podziale tekstu na mniejsze elementy, takie jak pojedyncze słowa lub całe zdania.
"""

import nltk
nltk.download('punkt_tab')

from nltk.tokenize import word_tokenize, sent_tokenize

text = """Wczoraj był piękny zachód słońca. Moja siostra lubi czytać książki.
Kupiłem nowy komputer do pracy. Czy znasz tego nowego sąsiada?
Mam ochotę na kawałek czekolady. Zobaczymy się jutro na obiedzie.
Lubię chodzić na długie spacery. Dzisiaj pada deszcz od rana.
W weekend pojadę do rodziców. Szukam pomysłu na ciekawy projekt."""

words = word_tokenize(text)
sentences = sent_tokenize(text)

print(words)
print(sentences)

"""uwanie stop words- wbudowane zestawy „stop words” umożliwiają pomijanie częstych słów, takich jak „i” czy „lub”, które mogą nie być istotne dla analizy."""

import nltk
nltk.download('stopwords')

text = """There was a beautiful sunset. My sister likes reading books. I bought a new computer for work. Do you know the new neighbor? I could go for some chocolate. We'll see each other for lunch tomorrow. I like going on long walks. It's been raining since morning. I'll go to my parents place over the weekend. I'm looking for an idea for an interesting project."""

words = nltk.tokenize.word_tokenize(text)
stop_words = set(nltk.corpus.stopwords.words("english"))
filtered_words = [word for word in words if word.lower() not in stop_words]

print(stop_words)
print(filtered_words)

"""Stemming i Lematyzacja- procesy te redukują słowa do ich form podstawowych. Stemming przycina końcówki słów, a lematyzacja zwraca słowa do ich form bazowych:"""

import nltk
from nltk.stem import PorterStemmer, WordNetLemmatizer
from nltk.corpus import wordnet

nltk.download('wordnet')
nltk.download('omw-1.4')

stemmer = PorterStemmer()
lemmatizer = WordNetLemmatizer()

words = ["running", "jumps", "easily", "studies", "better", "children"]

# Stemming
stemmed_words = [stemmer.stem(word) for word in words]
print("Stemmed words:", stemmed_words)

# Lemmatization (as verbs)
lem_words = [lemmatizer.lemmatize(word, pos=wordnet.VERB) for word in words]
print("Lemmatized words (as verbs):", lem_words)

# Lemmatization (as adjectives where applicable)
lem_words_adj = [lemmatizer.lemmatize(word, pos=wordnet.ADJ) for word in words]
print("Lemmatized words (as adjectives where applicable):", lem_words_adj)

"""4. Analiza składniowa i rozpoznawanie części mowy (POS tagging)- NLTK umożliwia oznaczanie części mowy, takich jak czasowniki, rzeczowniki, przymiotniki, co może pomóc w analizie struktury i znaczenia tekstu."""

import nltk
nltk.download('stopwords')
nltk.download('averaged_perceptron_tagger_eng')

from nltk import pos_tag

slowa = pos_tag(nltk.tokenize.word_tokenize( """There was a beautiful sunset.My sister likes reading books. """))


print(slowa)

"""Ekstrakcja nazw własnych i drzewa składniowe- narzędzia do analizy drzewa składniowego oraz wyodrębnianie nazw geograficznych, organizacji itp."""

import nltk
nltk.download('words')
nltk.download('maxent_ne_chunker')
nltk.download('maxent_ne_chunker_tab')

from nltk import ne_chunk
from nltk import pos_tag
import nltk.tokenize

named_entities = ne_chunk(pos_tag(nltk.tokenize.word_tokenize("""Musk is the founder of SpaceX and sends Falcon rockets into space.""")))


print(named_entities)

"""3.2 Biblioteka spaCy"""

!python -m spacy download pl_core_news_md

import spacy
nlp = spacy.load("pl_core_news_md")
text = "Elon Musk jest zalozycielem SpaceX i wysyla rakiety Falcon w kosmos."
doc = nlp(text)
tokens = [token.text for token in doc]
print(tokens)


for ent in doc.ents:
  print(ent.text, ent.label_)

for token in doc:
  print(f"Word: {token.text}, POS: {token.pos_}, Dependency: {token.dep_}")

lemmatized_words = [token.lemma_ for token in doc]
print(lemmatized_words)


slowo1 = nlp("obszar")
slowo2 = nlp("powierzchnia")
podob = slowo1.similarity(slowo2)
print(f"Podobienstwo: {podob}")

"""3.3 Biblioteka textblob"""

from textblob import TextBlob
text = "Python is amazing! I really enjoy programming."
blob = TextBlob(text)
sent = blob.sentiment
print(f"Polaryzacja: {sent.polarity}, Subiektywnosc: {sent.subjectivity}")

"""4 Korzystanie z zewnętrznych modeli"""

!pip install transformers torch
!pip install huggingface_hub

"""1. Analiza sentymentu"""

import numpy as np
from transformers import AutoTokenizer, AutoModelForSequenceClassification


id2label = {0: "negative", 1: "neutral", 2: "positive"}

model_name = "Voicelab/herbert-base-cased-sentiment"


tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSequenceClassification.from_pretrained(model_name)

input_text = ["Ale fajnie, spadł dzisiaj śnieg! Ulepimy dzisiaj bałwana?"]

encoding = tokenizer(
    input_text,
    add_special_tokens=True,
    return_token_type_ids=True,
    truncation=True,
    padding="max_length",
    return_attention_mask=True,
    return_tensors="pt",
)

output = model(**encoding).logits.to("cpu").detach().numpy()
prediction = id2label[np.argmax(output)]

print(input_text, "--->", prediction)

import logging
from transformers import pipeline
# Ustawienie poziomu logowania na ERROR, aby wyciszyc komunikaty informacyjne
logging.getLogger("transformers").setLevel(logging.ERROR)
# Uzycie analizy sentymentu z odpowiednim modelem
classifier = pipeline("sentiment-analysis", model="Voicelab/herbert-base-cased-sentiment")
result = classifier("Srednio lubie programowac w Pythonie!")
print(result)

"""2. Tłumaczenie tekstu"""

translator = pipeline("translation", model="Helsinki-NLP/opus-mt-pl-en")
result = translator("Elon Musk jest zalozycielem SpaceX i wysyla rakiety Falcon w kosmos.")
print(result)

"""3. Generowanie tekstu"""

generator = pipeline("text-generation", model="flax-community/papuGaPT2")
generator("Najlepszy jezyk programowania")

"""4. Mini Chatbot do rozmów"""

from transformers import AutoModelForCausalLM, AutoTokenizer
# Wczytaj model i tokenizer
tokenizer = AutoTokenizer.from_pretrained("microsoft/DialoGPT-medium")
model = AutoModelForCausalLM.from_pretrained("microsoft/DialoGPT-medium")
# Wejscie uzytkownika
input_text = "What do you know about the Python Language?"
input_ids = tokenizer.encode(input_text + tokenizer.eos_token, return_tensors= "pt")
# Generowanie odpowiedzi
response_ids = model.generate(input_ids, max_length=50, pad_token_id=tokenizer .eos_token_id)
response_text = tokenizer.decode(response_ids[0], skip_special_tokens=True)
# Usun tekst wejsciowy z odpowiedzi, aby uzyskac jedynie odpowiedz modelu
response_only = response_text[len(input_text):].strip()
print(response_only)

"""5.Zadania

2
"""

import nltk
nltk.download('words')
nltk.download('maxent_ne_chunker')
nltk.download('averaged_perceptron_tagger')
nltk.download('punkt')

from nltk import ne_chunk, pos_tag
from nltk.tokenize import word_tokenize

def extract_named_entities(text):
    words = word_tokenize(text)
    tagged_words = pos_tag(words)
    named_entities = ne_chunk(tagged_words)
    print("Rozpoznane nazwy własne i organizacje:")
    print(named_entities)

if __name__ == "__main__":
    user_text = input("Podaj tekst do analizy nazw własnych: ")
    extract_named_entities(user_text)

"""4. Zbuduj narzędzie do tłumaczenia tekstu polskiego na angielski z możliwością wielokrotnego użycia, dopóki użytkownik nie zdecyduje o zakończeniu."""

from transformers import pipeline

def translate_text():
    translator = pipeline("translation", model="Helsinki-NLP/opus-mt-pl-en")

    while True:
        user_text = input("Podaj tekst do tłumaczenia (lub wpisz 'exit' aby zakończyć): ")
        if user_text.lower() == 'exit':
            print("Zakończono tłumaczenie.")
            break
        result = translator(user_text)
        print("Tłumaczenie:", result[0]['translation_text'])

if __name__ == "__main__":
    translate_text()

"""Odszukaj na stronie https://huggingface.co/Helsinki-NLP modeli językowych tłumaczących z języka polskiego na niemiecki oraz z niemieckiego na polski a następnie przygotuj program tłumaczący pobierający tekst od użytkownika z możliwością wyboru kierunku tłumaczenia."""

from transformers import pipeline

def translate_text():
    pl_to_de = pipeline("translation", model="Helsinki-NLP/opus-mt-pl-de")
    de_to_pl = pipeline("translation", model="Helsinki-NLP/opus-mt-de-pl")

    while True:
        direction = input("Wybierz kierunek tłumaczenia (pl->de / de->pl) lub wpisz 'exit' aby zakończyć: ").strip().lower()
        if direction == 'exit':
            print("Zakończono tłumaczenie.")
            break
        elif direction not in ["pl->de", "de->pl"]:
            print("Niepoprawny wybór. Spróbuj ponownie.")
            continue

        user_text = input("Podaj tekst do tłumaczenia: ").strip()
        if not user_text:
            print("Wprowadzono pusty tekst. Spróbuj ponownie.")
            continue


        if direction == "pl->de":
            result = pl_to_de(user_text)
        else:
            result = de_to_pl(user_text)
        print("Tłumaczenie:", result[0]['translation_text'])

if __name__ == "__main__":
    translate_text()

"""6. Przeszukaj zasoby Hugging Face w celu znalezienia polskich modeli językowych. Wybierz dowolny model i spróbuj wykonać chatbota lub analizę sentymentu z jego użyciem."""

import numpy as np
from transformers import AutoTokenizer, AutoModelForSequenceClassification

id2label = {0: "negative", 1: "neutral", 2: "positive"}

tokenizer = AutoTokenizer.from_pretrained("Voicelab/herbert-base-cased-sentiment")
model = AutoModelForSequenceClassification.from_pretrained("Voicelab/herbert-base-cased-sentiment")

# Przykładowe zdanie do analizy
input_text = ["Ale fajnie, spadł dzisiaj śnieg! Ulepimy dziś bałwana?"]
encoding = tokenizer(
    input_text,
    add_special_tokens=True,
    return_token_type_ids=True,
    truncation=True,
    padding='max_length',
    return_attention_mask=True,
    return_tensors='pt',
)


output = model(**encoding).logits.to("cpu").detach().numpy()
prediction = id2label[np.argmax(output)]

# Wyświetlenie wyniku
print(f"Tekst: {input_text[0]}")
print(f"Sentyment: {prediction}")